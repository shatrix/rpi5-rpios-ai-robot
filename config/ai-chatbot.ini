[ollama]
# Ollama server configuration
# Use 'local' for local Ollama server, or 'IP:PORT' for network server (e.g., 192.168.2.170:11434)
ollama_host = local
# Vision model to use on network server (if ollama_host is not 'local')
network_vision_model = moondream
# Connection timeout for network Ollama (seconds)
network_timeout = 5

[llm]
# System prompt for concise answers (robot personality)
system_prompt = You are a helpful robot. Answer in 1 sentence maximum. Be direct and concise.
# Ollama models
text_model = llama3.2:1b
vision_model = moondream
max_tokens = 50
temperature = 0.7

[vosk]
# VOSK ASR settings
model_path = /usr/share/vosk-models/default
sample_rate = 16000

[audio]
# Audio device will be auto-detected by detect-audio.sh
# USB Audio Device is typically card 0 on RPi OS
microphone_device = plughw:0,0
speaker_device = auto
sample_rate = 16000

[camera]
enable = true
resolution = 640x480

[behavior]
# Auto-reset conversation after 5 minutes of inactivity
chat_history_timeout = 300
max_history_messages = 10
